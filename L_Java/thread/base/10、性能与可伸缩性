1、线程的主要目的是提高程序的运行性能。
    线程可以使程序更加充分地发挥系统的可用处理能力，从而提高系统的资源利用率。
    线程还可以使程序在运行现有任务的情况下立即开始处理新的任务，从而提高系统的相应性。

2、首先要保证程序能正确运行，然后仅当程序的性能需求和测试结果要求程序执行得更快时，才
    应该设法提高它的运行速度。

3、 提升性能意味着用更少的资源做更多的事情。
    当操作性能由于某种特定的资源而受限制时，我们通常该将操作称为资源密集型的操作，例如：
    CPU密集型、数据库密集型等。

4、与单线程相比，使用多个线程总会引入一些额外的性能开销。造成这些开销的操作包括：线程之间
    的协调（例如加锁、触发信号以及内存同步等），增加的上下文切换，线程的创建和销毁，以及线
    程的调度等。

5、要想通过并发来获得更好的性能，需要努力做好两件事情：更有效第利用现有处理资源，以及在出现
    新的处理资源时时程序尽可能地利用这些新资源。
    从性能监视的角度来看，CPU需要尽可能保持忙碌状态。
    如果程序是计算密集型的，那么可以通过增加处理器来提高性能。

6、应用程序的性能可以采用多个指标来衡量，；例如服务时间、延迟时间、吞吐量、效率、可伸缩性以及
    容量等。其中一些指标（服务时间、等待时间）用于衡量程序的“运行速度”，即某个指定任务单元需
    要“多块”才能处理完成。另一些指标（生产量、吞吐量）用于程序的“处理能力”，即在计算资源一
    定的情况下，能完成“多少”工作。

7、可伸缩性指的是：当增加计算资源时。（例如CPU、内存、存储容量或I/O带宽），程序的吞吐量或者处理
    能力相应地增加。

9、性能的这两个方面--“多块”和“多少”，是完全独立的，有时候甚至是相互矛盾的。

10、具有讽刺意味的是，大多数提高线程程序性能的技术，往往都会破坏可伸缩性。

11、对于服务器应用程序来说，“多少”这个方面--可伸缩性、吞吐量和生产量，往往比“多块”这个方面更
    受重视。

12、避免不成熟的优化。首先使程序正确，然后在提高运行速度——如果它还运行得不够快。

13、免费的perfbar应用程序可以给出CPU的忙碌程度信息。

14、在有些问题中，如果可用资源越多，那么问题的解决速度就越快。

15、Amdahl定律
    描述的是：在增加计算资源的情况下，程序在理论上能够实现最高加速比，这个值取决于程序中可并行组件与
    串行组件所占的比重。
    假定F是必须被串行执行的部分，那么根据Amdahl定律，在包含N个处理器的机器中，最高的加速比为：
        Speedup<= 1/(F+(1-F)/N)
    即使拥有无限多的CPU，加速比也不可能为10。

16、利用率的定义为：
    加速比除以处理器的数量。

17、所有有用的计算都会生成某种结果或者产生某种效应——如果不会，那么可以将他们作为“死代码”删除掉。

18、在所有并发程序中都包含一些串行部分。如果你认为在你的程序中不存在串行部分，那么可以在仔细检查一遍。

19、Amdahl定律的应用
    如果能准确估计出执行过程中串行部分所占的比例，那么Amdahl定律就能量化当有更多计算资源可用时的加速比。

20、锁分解
    将一个锁分解为两个锁
    如果有个锁需要保护多个互相独立的状态变量，那么可以将这个锁分解为多个锁，并且每个锁只保护一个变量，从而
    提高可伸缩性，并降低每个锁被请求的频率。

21、锁分段
    把一个锁分解为多个锁
    在某些情况下，可以将锁分解技术进一步扩展为多一组独立对象上的锁进行分解，这种情况被称为锁分段。
    锁分段的一个劣势在于：与采用单个锁来实现独占访问相比，要获取多个锁来实现独占访问将更加困难并且开销更高。

22、
    单线程程序即不存在线程调度，也不存在同步开销。而且不需要使用锁来保证数据结构的一致性。
    在多个线程的调度和协调过程中都需要一定的性能开销：对于为了提升性能而引入的线程来说，并
    行带来的性能提升必须超过并发程序导致的开销。

23、如果主线程是唯一的线程，那么他基本上不会被调度出去。

24、在JVM中和操作系统的代码中消耗越多的CPU时钟周期，应用程序的可用CPU时钟周期就越来越少。

25、在大多数通用的处理器中，上下文切换的开销相当于5000~10000个时钟周期，也就是几微秒。

26、UNIX系统的vmstat命令和Windows系统的perfmon工具都能报告上下文切换次数已经在内核中执行时
    间所占比例等信息。

27、内存栅栏可以刷新缓存，使缓存无效，刷新硬件的写缓冲，以及停止执行管道。
    内存栅栏可能同样会对性能带来直接的影响，应为他们将抑制一些编译器优化操作。
    在内存栅栏中，大多数操作都是不能被重排序的。

28、即使不进行逸出分析，编译器也可以执行锁粒度粗化操作，即将邻近的同步代码块用同一个锁合并起来。

29、如果有多个线程竞争同步带宽，那么所有使用了同步的线程都会受到影响。

30、串行操作会降低可伸缩性，并且上下文切换也会降低性能。
    在锁上发生竞争时将导致这两个问题，因此减少锁的竞争能够提高性能和可伸缩性。

31、在并发应用程序中，对可伸缩性的最要威胁就是独占方式的资源锁。

32、有两个因素将影响在锁上发生竞争的可能性：锁的请求频率，以及每次持有该锁的时间。
    如果二者的乘积很小，那么大多数获取锁的操作都不会发生竞争，因此在该锁上的竞争不会对可伸缩性造成严重影响。
    如果在锁上的请求量高，那么需要获取该锁的线程将阻塞并等待。在极端情况下，即使扔有大量工作等待完成，处理
    器也会被闲置。

33、降低锁的竞争程度
    减少锁的持有时间。
    降低锁的请求评率。
    使用带有协调机制的独占锁，这些机制允许更高的并发性。

34、
    如果有个锁需要保护多个互相独立的状态变量，那么可以将这个锁分解为多个锁，并且每个锁只保护一个变量，从而
    提高可伸缩性，并降低每个锁被请求的频率。

35、如果在锁上存在适中而不是激烈的竞争时，通过将一个锁分解为两个锁，能最大限度地提升性能。

36、锁分解和锁分段技术都能提高 可伸缩性，因为它们都能使不同的线程在不同的数据（或者同一个数据的不同部分）上
    操作，而不会相互干扰。如果程序采用锁分段技术，那么一定要表现出在锁上的竞争频率高于在锁保护的数据上发生竞
    争的频率。

37、热点域

38、当每个操作都请求多个变量时，锁的粒度将很难降低。这是在性能与可伸缩性之间相互制衡的另一个方面，一个常见的
    优化措施，例如将一些反复计算的结果缓存起来，都会引入一些“热点域”，而这些热点域往往会限制可伸缩性。

37、如果在类中只包含少量的热点域，并且这些域不会与其他变量参与到不变性条件中，那么用原子变量来替代它们能提高
    可伸缩性（通过减少算法中的热点域，可以提高可伸缩性——虽然原子变量能降低热点域的更新开销，但并不能完全消除）

38、当任务在运行和阻塞这两个状态之间装换时，就相当于一次上下文切换。

39、请求服务的时间不应该过长，主要有一下原因
    服务时间影响服务质量：服务时间越长，就意味着有程序在获得结果时需要等待更长的时间。
    更重要的是，服务时间越长，也就意味着存在越多的锁竞争。

40、在代码的上下文切换次数越多，吞吐量就越低。

41、通过将I/O操作从处理请求的线程中分离出来，可以缩短处理请求的平均服务时间。






















































































































